import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from dateutil import parser

st.set_page_config(page_title="YouTube Mini Analytics", page_icon="ğŸ“ˆ", layout="wide")
st.title("ğŸ“ˆ YouTube Mini Analytics â€” CSV Starter")
st.caption("ì´ˆë³´ììš©: CSVë§Œ ì—…ë¡œë“œí•˜ë©´ í•µì‹¬ ì§€í‘œë¥¼ ìë™ ìš”ì•½í•©ë‹ˆë‹¤. API ì—°ê²°ì€ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì¶”ê°€ ì˜ˆì •")

with st.sidebar:
    st.header("ëª¨ë“œ")
    mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["CSV ì—…ë¡œë“œ (ê¶Œì¥)", "API(ì¤€ë¹„ì¤‘)"])
    st.markdown("---")
    st.subheader("ì •ë ¬ ê¸°ì¤€")
    sort_key = st.selectbox("TOP ë¦¬ìŠ¤íŠ¸ ì •ë ¬", ["views","watch_time","avg_view_duration","impressions","ctr","subs"], index=0)
    top_k = st.slider("ìƒìœ„ Nê°œ", 5, 50, 10)

def detect_col(df, candidates):
    cols = list(df.columns)
    lower_map = {c.lower(): c for c in cols}
    for cand in candidates:
        if cand in df.columns: return cand
        lc = cand.lower()
        if lc in lower_map: return lower_map[lc]
        for c in cols:
            if lc in c.lower(): return c
    return None

def coerce_numeric(s):
    if s is None: return None
    return pd.to_numeric(s, errors='coerce')

@st.cache_data
def load_csv(uploaded_file):
    return pd.read_csv(uploaded_file)

if mode.startswith("CSV"):
    st.subheader("1) CSV ì—…ë¡œë“œ")
    csv = st.file_uploader("YouTube Studioì—ì„œ ë‚´ë³´ë‚¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["csv"], accept_multiple_files=True)
    map_file = st.file_uploader("(ì„ íƒ) ì˜ìƒ ê¸¸ì´/íƒ€ì… ë§¤í•‘ CSV ì—…ë¡œë“œ â€” 'Video title, duration_sec, type' ì»¬ëŸ¼", type=["csv"], accept_multiple_files=False)

    if csv:
        dfs = []
        for f in csv:
            try:
                df = load_csv(f); df["__source_file__"] = f.name; dfs.append(df)
            except Exception as e:
                st.warning(f"íŒŒì¼ `{f.name}` ì½ê¸° ì‹¤íŒ¨: {e}")
        if not dfs: st.stop()
        raw = pd.concat(dfs, ignore_index=True)

        title_col = detect_col(raw, ["Video title","ì œëª©","ë™ì˜ìƒ","Video","Title"]) or "Video title"
        date_col  = detect_col(raw, ["Date","ë‚ ì§œ","ì¼ì"])
        views_col = detect_col(raw, ["Views","ì¡°íšŒìˆ˜"])
        wt_col    = detect_col(raw, ["Watch time (hours)","ì‹œì²­ ì‹œê°„(ì‹œê°„)","Watch time","ì‹œì²­ ì‹œê°„"])
        avd_col   = detect_col(raw, ["Average view duration","í‰ê·  ì‹œì²­ ì‹œê°„","Avg view duration"])
        impr_col  = detect_col(raw, ["Impressions","ë…¸ì¶œìˆ˜"])
        ctr_col   = detect_col(raw, ["Impressions click-through rate","ë…¸ì¶œ ëŒ€ë¹„ í´ë¦­ë¥ ","CTR"])
        subs_col  = detect_col(raw, ["Subscribers","êµ¬ë…ì","Subscribers gained","êµ¬ë…ì ì¦ê°€"])

        work = raw.copy()
        for c in [views_col, wt_col, avd_col, impr_col, ctr_col, subs_col]:
            if c and c in work.columns:
                work[c] = coerce_numeric(work[c].astype(str).str.replace('%','', regex=False).str.replace(',',''))
        if date_col and date_col in work.columns:
            def parse_date(x):
                try: return parser.parse(str(x)).date()
                except Exception: return pd.NaT
            work["__date__"] = work[date_col].apply(parse_date)

        work = work.rename(columns={title_col: "Video title"})
        if map_file is not None:
            m = load_csv(map_file)
            cols_needed = [c for c in ["Video title","duration_sec","type"] if c in m.columns]
            work = work.merge(m[cols_needed], on="Video title", how="left")

        if "type" not in work.columns:
            if "duration_sec" in work.columns:
                work["type"] = np.where(work["duration_sec"].astype(float) <= 60, "Shorts", "Longform")
            else:
                work["type"] = np.where(work["Video title"].str.contains("#shorts", case=False, na=False), "Shorts", "Unknown")

        st.markdown("---"); st.subheader("2) í•µì‹¬ KPI ìš”ì•½")
        def safe_sum(col): return work[col].sum() if col in work else np.nan
        def safe_mean(col): return work[col].mean() if col in work else np.nan
        total_views, total_wt, avg_ctr, subs_sum = safe_sum(views_col), safe_sum(wt_col), safe_mean(ctr_col), safe_sum(subs_col)
        k1,k2,k3,k4 = st.columns(4)
        k1.metric("ì´ ì¡°íšŒìˆ˜", f"{int(total_views):,}" if pd.notna(total_views) else "-")
        k2.metric("ì´ ì‹œì²­ì‹œê°„(ì‹œê°„)", f"{total_wt:,.1f}" if pd.notna(total_wt) else "-")
        k3.metric("í‰ê·  CTR(%)", f"{avg_ctr:,.2f}" if pd.notna(avg_ctr) else "-")
        k4.metric("êµ¬ë…ì ì¦ê°", f"{int(subs_sum):,}" if pd.notna(subs_sum) else "-")

        st.subheader("3) ë¡±í¼ vs ìˆì¸  ë¹„êµ")
        if "type" in work:
            rename_map = {}
            if views_col: rename_map[views_col] = 'views'
            if wt_col: rename_map[wt_col] = 'watch_time'
            if avd_col: rename_map[avd_col] = 'avg_view_duration'
            if impr_col: rename_map[impr_col] = 'impressions'
            if ctr_col: rename_map[ctr_col] = 'ctr'
            if subs_col: rename_map[subs_col] = 'subs'
            w2 = work.rename(columns=rename_map)
            g = w2.groupby('type').agg({
                'views':'sum' if 'views' in w2 else 'first',
                'watch_time':'sum' if 'watch_time' in w2 else 'first',
                'avg_view_duration':'mean' if 'avg_view_duration' in w2 else 'first',
                'impressions':'sum' if 'impressions' in w2 else 'first',
                'ctr':'mean' if 'ctr' in w2 else 'first',
                'subs':'sum' if 'subs' in w2 else 'first',
            })
            st.dataframe(g, use_container_width=True)

            if "__date__" in w2 and 'views' in w2:
                daily = w2.dropna(subset=["__date__"]).groupby(["__date__","type"]).agg({'views':'sum'}).reset_index()
                fig, ax = plt.subplots()
                for t, sub in daily.groupby('type'):
                    ax.plot(sub['__date__'], sub['views'], label=t)
                ax.set_title('ì¼ìë³„ ì¡°íšŒìˆ˜ ì¶”ì´ (íƒ€ì…ë³„)')
                ax.set_xlabel('ë‚ ì§œ'); ax.set_ylabel('ì¡°íšŒìˆ˜'); ax.legend()
                st.pyplot(fig)

        st.markdown("---"); st.subheader("4) ìƒìœ„ ì˜ìƒ ë¶„ì„")
        if "Video title" in work:
            grp = work.groupby("Video title").agg({
                views_col: 'sum' if views_col in work else 'first',
                wt_col: 'sum' if wt_col in work else 'first',
                avd_col: 'mean' if avd_col in work else 'first',
                impr_col: 'sum' if impr_col in work else 'first',
                ctr_col: 'mean' if ctr_col in work else 'first',
                subs_col: 'sum' if subs_col in work else 'first',
                'type': 'first' if 'type' in work else 'first'
            }).reset_index()

            rename_map = {}
            if views_col: rename_map[views_col] = 'views'
            if wt_col: rename_map[wt_col] = 'watch_time'
            if avd_col: rename_map[avd_col] = 'avg_view_duration'
            if impr_col: rename_map[impr_col] = 'impressions'
            if ctr_col: rename_map[ctr_col] = 'ctr'
            if subs_col: rename_map[subs_col] = 'subs'
            grp = grp.rename(columns=rename_map)

            sort_key_use = sort_key if sort_key in grp.columns else 'views'
            grp = grp.sort_values(sort_key_use, ascending=False).head(top_k)
            st.dataframe(grp, use_container_width=True)
        else:
            st.info("ì˜ìƒ ì œëª© ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. CSV ë‚´ë³´ë‚´ê¸° ì˜µì…˜ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

        st.markdown("---"); st.subheader("5) ê°„ë‹¨ ì¸ì‚¬ì´íŠ¸ ì œì•ˆ")
        tips = []
        if 'ctr' in locals().get('grp', pd.DataFrame()).columns:
            high_ctr = grp.nlargest(3, 'ctr') if 'ctr' in grp else pd.DataFrame()
            if not high_ctr.empty:
                tips.append("CTR ìƒìœ„ ì˜ìƒì˜ ì œëª©/ì¸ë„¤ì¼ ê³µí†µ íŒ¨í„´ì„ ë‹¤ìŒ ì—…ë¡œë“œì— ë°˜ì˜í•´ ë³´ì„¸ìš”.")
        if 'avg_view_duration' in locals().get('grp', pd.DataFrame()).columns:
            tips.append("í‰ê·  ì‹œì²­ì‹œê°„ì´ ë†’ì€ ì˜ìƒì˜ ì˜¤í”„ë‹ ê¸¸ì´ì™€ ì „í™˜ íƒ€ì´ë°ì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ì„¸ìš”.")
        if 'impressions' in locals().get('grp', pd.DataFrame()).columns and 'ctr' in locals().get('grp', pd.DataFrame()).columns:
            tips.append("ë…¸ì¶œìˆ˜ëŠ” ë†’ì§€ë§Œ CTRì´ ë‚®ì€ ì˜ìƒì€ ì¸ë„¤ì¼/ì œëª© A/B í…ŒìŠ¤íŠ¸ ëŒ€ìƒì…ë‹ˆë‹¤.")
        if 'type' in locals().get('grp', pd.DataFrame()).columns:
            tips.append("Shortsì™€ Longform ê°ê° TOP5ì˜ ê³µí†µ í‚¤ì›Œë“œë¥¼ ë¹„êµí•´ ë³´ì„¸ìš”.")
        if not tips:
            tips.append("ë°ì´í„° ì—´ ì´ë¦„ì„ ë” í’ë¶€í•˜ê²Œ í¬í•¨í•œ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ì¸ì‚¬ì´íŠ¸ê°€ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.")
        for t in tips:
            st.write("â€¢ ", t)
else:
    st.info("API ëª¨ë“œëŠ” ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. CSV ëª¨ë“œë¡œ ë¨¼ì € ì‹œì‘í•´ ë³´ì„¸ìš”. (YouTube Analytics API ì—°ë™ì€ ì°¨í›„ ì—…ë°ì´íŠ¸)")
